# -*- coding: utf-8 -*-
"""AutoEncoders_Supervised

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DDij0mpJBCmsFMiYB8QvA5h-hscoFBNZ
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model

# Download the dataset
dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header = None)
raw_data = dataframe.values
dataframe.head()

raw_data

# The last element contains the labels
labels = raw_data[:, -1]

# The other data points are the electrocadriogram data
data = raw_data[:, 0:-1]

train_data, test_data, train_labels, test_labels = train_test_split(
    data, labels, test_size=0.2, random_state=21
)   # random_state is only for reproducing the results 21 is just some number,  but keep it same

labels

train_labels

data

"""Normalize the data to [0,1] to improve training accuracy."""

min_value = tf.reduce_min(train_data)   # get the minimum value from the train_data
max_value = tf.reduce_max(train_data)  # get the max value
print(min_value)
print()
print(max_value)
tf.print(train_data)
print()

train_data = (train_data - min_value) / (max_value - min_value)
test_data = (test_data - min_value) / (max_value - min_value)

train_data = tf.cast(train_data, tf.float32)
test_data = tf.cast(test_data, tf.float32)

tf.print(train_data)

"""You will train the autoencoder using only the normal rhythms, which are labeled in this dataset as 1. Separate the normal rhythms from the abnormal rhythms"""

train_labels = train_labels.astype(bool)
test_labels = test_labels.astype(bool)

print(train_labels)

normal_train_data = train_data[train_labels]
normal_test_data = test_data[test_labels]

anomalous_train_data = train_data[~train_labels]
anomalous_test_data = test_data[~test_labels]

normal_train_data

# Plot the ECG of the first list [0]
plt.grid()
plt.plot(np.arange(140), normal_train_data[0])
plt.title('A Normal ECG')
plt.show()

# Plot an anomalous ECG
plt.grid()
plt.plot(np.arange(140), anomalous_train_data[0])
plt.title('An Anomalous ECG')
plt.show()

print(normal_train_data)
print(normal_train_data[0])

class AnomalyDetector(Model):
  def __init__(self):
    super(AnomalyDetector, self).__init__()
    self.encoder = tf.keras.Sequential([
        layers.Dense(32, activation='relu'),
        layers.Dense(16, activation="relu"),
        layers.Dense(8, activation="relu")]) # Smallest Layer in the architecture Defined Here

    self.decoder = tf.keras.Sequential([
      layers.Dense(16, activation="relu"),
      layers.Dense(32, activation="relu"),
      layers.Dense(140, activation="sigmoid")])  # here 140 is to map output to the input features 
    
  def call(self, x):
    encoded = self.encoder(x)  # takes the input x, encode it ,  feed the ecoder output to the decoder and decode it
    decoded = self.decoder(encoded)
    return decoded

autoencoder = AnomalyDetector()

autoencoder.compile(optimizer='adam', loss = 'mae')

"""autoencoder is trained using only the normal ECGs, but is evaluated using the full test set."""

history = autoencoder.fit(normal_train_data, normal_train_data,
                          epochs = 20,
                          batch_size=512,
                          validation_data=(test_data, test_data),
                          shuffle=True)

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()

"""
classify an ECG as anomalous if the reconstruction error is greater than one standard deviation from the normal training examples. First, let's plot a normal ECG from the training set, the reconstruction after it's encoded and decoded by the autoencoder, and the reconstruction error."""

encoded_imgs = autoencoder.encoder(normal_test_data).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

encoded_imgs

decoded_imgs

# Test on normal test data

plt.plot(normal_test_data[0], 'b')   # normal test data
plt.plot(decoded_imgs[0], 'r')   # decoded on 'normal test data'
plt.fill_between(np.arange(140), decoded_imgs[0], normal_test_data[0], color='lightcoral')
plt.legend(labels =['Input', 'Reconstruction', 'Error'])
plt.show()

# Create a similar plot, this time for an anomalous test example
encoded_imgs = autoencoder.encoder(anomalous_test_data).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

plt.plot(anomalous_test_data[0], 'b')
plt.plot(decoded_imgs[0], 'r')
plt.fill_between(np.arange(140), decoded_imgs[0], anomalous_test_data[0], color='lightcoral')
plt.legend(labels=['Input', 'Reconstruction', 'Error'])
plt.show()

"""Detect anomalies by calculating whether the reconstruction loss is greater than a fixed threshold, calculate the mean average error for normal examples from the training set, then classify future examples as anomalous if the reconstruction error is higher than one standard deviation from the training set."""

# Plot the reconstruction error on normal ECGs from the training set
reconstructions = autoencoder.predict(normal_train_data)
train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)

plt.hist(train_loss, bins=50)
plt.xlabel('Train Loss')
plt.ylabel('No of examples')
plt.show()
print(reconstructions)
print()
print(train_loss)

# Choose a threshold value that is one standard deviations above the mean.
threshold = np.mean(train_loss) + np.std(train_loss)
print('Threshold: ', threshold)

"""There are other strategies that could be use to select a threshold value above which test examples should be classified as anomalous, the correct approach will depend on the dataset. 

 examine the recontruction error for the anomalous examples in the test set, most have greater reconstruction error than the threshold. By varing the threshold, adjust the precision and recall of classifier.
"""

reconstructions = autoencoder.predict(anomalous_test_data)
test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)

plt.hist(test_loss, bins = 50)
plt.xlabel('Test Loss')
plt.ylabel('No of examples')
plt.show()

# Classify an ECG as an anomaly if the reconstruction error is greater than the threshold.
def predict(model, data, threshold):
  reconstructions = model(data)
  loss = tf.keras.losses.mae(reconstructions, data)
  return tf.math.less(loss, threshold), loss       # math.less = returns truth value if loss is less than threshold

def print_stats(predictions, labels):
  print('Accuracy = {}'.format(accuracy_score(labels, predictions)))
  print("Precision = {}".format(precision_score(labels, predictions)))
  print('Recall = {}'.format(recall_score(labels, predictions)))

preds, scores = predict(autoencoder, test_data, threshold)
print_stats(preds, test_labels)
print()
print(preds)
print()
print(scores)

"""ROC and AUC Metrics
We've created a fairly accurate model for anomaly detection but our accuracy is highly dependant on the threshold we select.

What if we wanted to evaluate how different thresholds impact our true positive and false positive rates?

Receiver Operating Characteristic (ROC) plots allows us to visualize the tradeoff between predicting anomalies as normal (false positives) and predicting normal data as an anomaly (false negative). Remember that normal rhythms are labeled as 1 in this dataset.
"""

fpr = []   # false positive rate
tpr = []   # true positive rate

# the test labels are flipped to match how the roc_curve function expects them.
flipped_labels = 1 - test_labels
fpr, tpr, _ = roc_curve(flipped_labels, scores)   # ROC curve plots tpr vs. fpr at different classification thresholds
plt.figure()    # area under the ROC curve measures the quality of the model's predictions irrespective of what classification threshold is chosen.
lw = 2        # ranges in value from 0 to 1. A model whose predictions are 100% wrong has an area of 0.0; one whose predictions are 100% correct has an area of 1.0.
plt.plot(fpr, tpr, color='darkorange',
         lw = lw, label='ROC curve')   #  The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')   # at diagonal, fpr == tpr
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

roc_auc = auc(fpr, tpr)   
print(roc_auc)